{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sklearn in c:\\users\\apula\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (0.0)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\apula\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from sklearn) (0.22.2.post1)\n",
      "Requirement already satisfied: joblib>=0.11 in c:\\users\\apula\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from scikit-learn->sklearn) (0.14.1)\n",
      "Requirement already satisfied: scipy>=0.17.0 in c:\\users\\apula\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from scikit-learn->sklearn) (1.4.1)\n",
      "Requirement already satisfied: numpy>=1.11.0 in c:\\users\\apula\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from scikit-learn->sklearn) (1.18.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: matplotlib in c:\\users\\apula\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (3.2.0)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in c:\\users\\apula\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from matplotlib) (2.8.1)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\apula\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from matplotlib) (1.1.0)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\apula\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from matplotlib) (0.10.0)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in c:\\users\\apula\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from matplotlib) (2.4.6)\n",
      "Requirement already satisfied: numpy>=1.11 in c:\\users\\apula\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from matplotlib) (1.18.1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\apula\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from python-dateutil>=2.1->matplotlib) (1.14.0)\n",
      "Requirement already satisfied: setuptools in c:\\users\\apula\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from kiwisolver>=1.0.1->matplotlib) (46.0.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "#import csvnltk.download('stopwords')\n",
    "import re\n",
    "import unicodedata\n",
    "import numpy as np\n",
    "#from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "from nltk.stem import SnowballStemmer\n",
    "import time\n",
    "import scipy.sparse\n",
    "import warnings\n",
    "\n",
    "#classifiers\n",
    "import pickle\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "from sklearn.metrics import classification_report, f1_score, accuracy_score, confusion_matrix\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "\n",
    "#graphs\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#parallel\n",
    "from sklearn.externals.joblib import Parallel, delayed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\apula\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading data into memory\n",
    "In the following section, we load the training and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "datasets were loaded 131940 54976\n"
     ]
    }
   ],
   "source": [
    "df_train = pd.read_csv('./data/train', sep='\\t', index_col=0)\n",
    "df_test = pd.read_csv('./data/test', sep='\\t', index_col=0)\n",
    "\n",
    "Xtrain=df_train['text']\n",
    "Ytrain=df_train['label']\n",
    "\n",
    "Xtest=df_test['text']\n",
    "Ytest=df_test['label']\n",
    "print('datasets were loaded', len(df_train), len(df_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_train.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we define \"split_into_tokens\", function to process the text giving as result a list of tokens where the following steps have been made:\n",
    "<li> Accents are removed\n",
    "<li> Non-alphanumeric characters are filtered\n",
    "<li> Shift to lower case and split text in tokens\n",
    "<li> Deleted stopwords and replacement of the remaining words by their root (stemming)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_into_tokens(text):\n",
    "    #stemmer = SnowballStemmer('spanish')\n",
    "    stemmer = None\n",
    "    min_length = 3\n",
    "    # 1. Remove accent marks\n",
    "    review_text = ''.join((c for c in unicodedata.normalize('NFD',str(text)) if unicodedata.category(c) != 'Mn'))\n",
    "    #\n",
    "    # 2. Remove non-alphanumeric\n",
    "    #letters_only = re.sub(\"[^A-Za-z0-9]\", \" \", review_text) \n",
    "    letters_only = re.sub(\"[^\\w\\d]\", \" \", review_text) \n",
    "    #\n",
    "    # 2. Convert to lower case, split into individual words\n",
    "    words = letters_only.lower().split()                             \n",
    "    #\n",
    "    # 3. In Python, searching a set is much faster than searching\n",
    "    #   a list, so convert the stop words to a set\n",
    "    stops = set(stopwords.words(\"spanish\"))                  \n",
    "    # \n",
    "    # 4. Remove stop words and apply or not stemming\n",
    "    if stemmer:\n",
    "        filtered_tokens = [stemmer.stem(w) for w in words if not w in stops and len(w)>=min_length]\n",
    "    else:\n",
    "        filtered_tokens = [w for w in words if not w in stops and len(w)>=min_length]\n",
    "    #\n",
    "    # 5. return the result\n",
    "    return filtered_tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The \"trainModel\" function receives the following arguments: the name of the classification algorithm, the class, its parameters, and the data sets. This function trains the model and returns a tuple with the name of the algorithm and the model already trained."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainModel(name, clazz, params, Xtrain, Ytrain):\n",
    "    print(\"training \", name)\n",
    "    model = clazz(**params)\n",
    "    start = time.time() # Start time\n",
    "    model.fit(Xtrain, Ytrain)\n",
    "    end = time.time()\n",
    "    elapsed = end - start\n",
    "    print(\"-> done \", name, \" - Time taken for training:\", elapsed, \"seconds\")\n",
    "    return (name, model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## \"Classical\" algorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, we create a dictionary that contains all the necessary data of the classification algorithms that are going to be used, as well as the parameters of each one of them. (In case the parameters are not indicated, those configured by default in scikit-learn are used)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"estimators = {\"KNeighbors\": (KNeighborsClassifier, {}),\n",
    "              \"MultinomialNB\" : (MultinomialNB, {}),\n",
    "              \"RandomForest\" : (RandomForestClassifier, {\"n_estimators\":100}),\n",
    "              \"LogisticRegression\" : (LogisticRegression, {}),\n",
    "              \"MLP\" : (MLPClassifier, {\"hidden_layer_sizes\":100}),\n",
    "              \"SVM\" : (SVC, {\"cache_size\":1000}),\n",
    "              \"LinearSVC\" : (LinearSVC, {})\n",
    "             }\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimators1 = {\"KNeighbors\": (KNeighborsClassifier, {}),\n",
    "              \"MultinomialNB\" : (MultinomialNB, {}),\n",
    "              \"RandomForest\" : (RandomForestClassifier, {\"n_estimators\":100}),\n",
    "              \"LogisticRegression\" : (LogisticRegression, {})\n",
    "             }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimators2 = {\"MLP\" : (MLPClassifier, {\"hidden_layer_sizes\":100}),\n",
    "              \"SVM\" : (SVC, {\"cache_size\":1000}),\n",
    "              \"LinearSVC\" : (LinearSVC, {})\n",
    "             }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bag of words  (unbalanced, with all \"classic\" algorithms)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, training and test data are transformed into a bag of words, going from a set of tokens to a set of occurrences per token."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "import nltk\n",
    "#from nltk import nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creando matriz de bolsa de palabras...\n",
      "Wall time: 1min 56s\n",
      "Wall time: 1min 55s\n",
      "Wall time: 46.6 s\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "bow = CountVectorizer(analyzer=split_into_tokens)\n",
    "\n",
    "print(\"Creando matriz de bolsa de palabras...\")\n",
    "\n",
    "%time bow.fit(Xtrain, Ytrain)\n",
    "%time Xtrain_bow = bow.transform(Xtrain)\n",
    "%time Xtest_bow = bow.transform(Xtest)\n",
    "\n",
    "scipy.sparse.save_npz('data/Xtrain_bow.npz', Xtrain_bow)\n",
    "scipy.sparse.save_npz('data/Xtest_bow.npz', Xtest_bow) \"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This section, loads in memory the bags of words. Use only if you have previously obtained the bags of words and do not have them loaded into memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtest_bow = scipy.sparse.load_npz('data/Xtest_bow.npz').astype(np.int16, casting='same_kind')\n",
    "Xtrain_bow = scipy.sparse.load_npz('data/Xtrain_bow.npz').astype(np.int16, casting='same_kind')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we create as many processes as we have estimators. These processes will be in charge of training the different models in parallel.<br> \n",
    "As a result, we get a list of tuples formed by: (the name of the algorithm, the model already trained)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#models = Parallel(n_jobs=len(estimators))(delayed(trainModel)(name, clazz, params, Xtrain_bow, Ytrain) for (name, (clazz, params)) in estimators.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "models1 = Parallel(n_jobs=len(estimators1))(delayed(trainModel)(name, clazz, params, Xtrain_bow, Ytrain) for (name, (clazz, params)) in estimators1.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('KNeighbors', KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "                     metric_params=None, n_jobs=None, n_neighbors=5, p=2,\n",
      "                     weights='uniform')), ('MultinomialNB', MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)), ('RandomForest', RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
      "                       criterion='gini', max_depth=None, max_features='auto',\n",
      "                       max_leaf_nodes=None, max_samples=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, n_estimators=100,\n",
      "                       n_jobs=None, oob_score=False, random_state=None,\n",
      "                       verbose=0, warm_start=False)), ('LogisticRegression', LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
      "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
      "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
      "                   warm_start=False))]\n"
     ]
    }
   ],
   "source": [
    "print(models1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "models2 = Parallel(n_jobs=len(estimators2))(delayed(trainModel)(name, clazz, params, Xtrain_bow, Ytrain) for (name, (clazz, params)) in estimators2.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('MLP', MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
      "              beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "              hidden_layer_sizes=100, learning_rate='constant',\n",
      "              learning_rate_init=0.001, max_fun=15000, max_iter=200,\n",
      "              momentum=0.9, n_iter_no_change=10, nesterovs_momentum=True,\n",
      "              power_t=0.5, random_state=None, shuffle=True, solver='adam',\n",
      "              tol=0.0001, validation_fraction=0.1, verbose=False,\n",
      "              warm_start=False)), ('SVM', SVC(C=1.0, break_ties=False, cache_size=1000, class_weight=None, coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='rbf',\n",
      "    max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "    tol=0.001, verbose=False)), ('LinearSVC', LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n",
      "          intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
      "          multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
      "          verbose=0))]\n"
     ]
    }
   ],
   "source": [
    "print(models2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once the models are trained, we obtain the labels from the test set and evaluate the results of each of them. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Obteniendo resultados:\")\n",
    "for (name, model) in models:\n",
    "    start = time.time() # Star t time\n",
    "    if name == \"KNeighbors\":\n",
    "        result = [y for x in [Xtest_bow[i:i+5000,:] for i in range(0,Xtest_bow.shape[0],5000)] for y in model.predict(x)]\n",
    "    else:\n",
    "        result = model.predict(Xtest_bow)\n",
    "    end = time.time()\n",
    "    elapsed = end - start\n",
    "    print(\"---------- Modelo: \", name, \" ---------- Time taken for prediction:\", elapsed,\"seconds\\n\", classification_report(Ytest, result, digits=4), \"\\n\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Obteniendo resultados:\n",
      "---------- Modelo:  KNeighbors  ---------- Time taken for prediction: 601.23597240448 seconds\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "       False     0.9982    1.0000    0.9991     54473\n",
      "        True     1.0000    0.8072    0.8933       503\n",
      "\n",
      "    accuracy                         0.9982     54976\n",
      "   macro avg     0.9991    0.9036    0.9462     54976\n",
      "weighted avg     0.9982    0.9982    0.9981     54976\n",
      " \n",
      "\n",
      "{'False': {'precision': 0.9982224665567161, 'recall': 1.0, 'f1-score': 0.9991104426694056, 'support': 54473}, 'True': {'precision': 1.0, 'recall': 0.8071570576540755, 'f1-score': 0.8932893289328934, 'support': 503}, 'accuracy': 0.9982355937136205, 'macro avg': {'precision': 0.999111233278358, 'recall': 0.9035785288270377, 'f1-score': 0.9461998858011496, 'support': 54976}, 'weighted avg': {'precision': 0.998238730004802, 'recall': 0.9982355937136205, 'f1-score': 0.9981422379944663, 'support': 54976}}\n",
      "---------- Modelo:  MultinomialNB  ---------- Time taken for prediction: 0.0805208683013916 seconds\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "       False     0.9992    0.9986    0.9989     54473\n",
      "        True     0.8598    0.9145    0.8863       503\n",
      "\n",
      "    accuracy                         0.9979     54976\n",
      "   macro avg     0.9295    0.9566    0.9426     54976\n",
      "weighted avg     0.9979    0.9979    0.9979     54976\n",
      " \n",
      "\n",
      "{'False': {'precision': 0.9992101541117907, 'recall': 0.9986231711122942, 'f1-score': 0.998916576381365, 'support': 54473}, 'True': {'precision': 0.8598130841121495, 'recall': 0.9145129224652088, 'f1-score': 0.8863198458574182, 'support': 503}, 'accuracy': 0.9978536088474971, 'macro avg': {'precision': 0.9295116191119701, 'recall': 0.9565680467887514, 'f1-score': 0.9426182111193916, 'support': 54976}, 'weighted avg': {'precision': 0.9979347480034922, 'recall': 0.9978536088474971, 'f1-score': 0.9978863785595237, 'support': 54976}}\n",
      "---------- Modelo:  RandomForest  ---------- Time taken for prediction: 3.998415946960449 seconds\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "       False     0.9989    1.0000    0.9994     54473\n",
      "        True     1.0000    0.8807    0.9366       503\n",
      "\n",
      "    accuracy                         0.9989     54976\n",
      "   macro avg     0.9994    0.9404    0.9680     54976\n",
      "weighted avg     0.9989    0.9989    0.9989     54976\n",
      " \n",
      "\n",
      "{'False': {'precision': 0.9988997487759705, 'recall': 1.0, 'f1-score': 0.9994495715832156, 'support': 54473}, 'True': {'precision': 1.0, 'recall': 0.8807157057654076, 'f1-score': 0.9365750528541227, 'support': 503}, 'accuracy': 0.9989086146682189, 'macro avg': {'precision': 0.9994498743879853, 'recall': 0.9403578528827038, 'f1-score': 0.9680123122186691, 'support': 54976}, 'weighted avg': {'precision': 0.998909815466266, 'recall': 0.9989086146682189, 'f1-score': 0.998874304504477, 'support': 54976}}\n",
      "---------- Modelo:  LogisticRegression  ---------- Time taken for prediction: 0.046863555908203125 seconds\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "       False     0.9993    0.9997    0.9995     54473\n",
      "        True     0.9689    0.9284    0.9482       503\n",
      "\n",
      "    accuracy                         0.9991     54976\n",
      "   macro avg     0.9841    0.9641    0.9739     54976\n",
      "weighted avg     0.9991    0.9991    0.9991     54976\n",
      " \n",
      "\n",
      "{'False': {'precision': 0.9993393768121261, 'recall': 0.9997246342224588, 'f1-score': 0.999531968394101, 'support': 54473}, 'True': {'precision': 0.9688796680497925, 'recall': 0.9284294234592445, 'f1-score': 0.9482233502538071, 'support': 503}, 'accuracy': 0.999072322467986, 'macro avg': {'precision': 0.9841095224309593, 'recall': 0.9640770288408517, 'f1-score': 0.973877659323954, 'support': 54976}, 'weighted avg': {'precision': 0.9990606873202122, 'recall': 0.999072322467986, 'f1-score': 0.9990625229101703, 'support': 54976}}\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "print(\"Obteniendo resultados:\")\n",
    "for (name, model) in models1:\n",
    "    start = time.time() # Star t time\n",
    "    if name ==\"KNeighbors\": \n",
    "        result = [y for x in [Xtest_bow[i:i+5000,:] for i in range(0,Xtest_bow.shape[0],5000)] for y in model.predict(x)]\n",
    "    else:\n",
    "        result = model.predict(Xtest_bow)\n",
    "    end = time.time()\n",
    "    elapsed = end - start   \n",
    "    print(\"---------- Modelo: \", name, \" ---------- Time taken for prediction:\", elapsed,\"seconds\\n\", classification_report(Ytest, result, digits=4), \"\\n\")\n",
    "    \n",
    "    #Save classification report and trained model to BoW folder\n",
    "    if name ==\"KNeighbors\": \n",
    "        report_KNeighbors = classification_report(Ytest, result, digits=4, output_dict=True)\n",
    "        print(report_KNeighbors)\n",
    "        dataframe = pd.DataFrame.from_dict(report_KNeighbors)\n",
    "        dataframe.to_csv('BoW/KNeighbors_clasification_report.csv', index=True)\n",
    "        save_classifier = open('BoW/KNeighbors_classifier.pickle', 'wb')  #write in bytes\n",
    "        pickle.dump(result, save_classifier)\n",
    "        save_classifier.close()\n",
    "    elif name ==\"MultinomialNB\":\n",
    "        report_MultinomialNB = classification_report(Ytest, result, digits=4, output_dict=True)\n",
    "        print(report_MultinomialNB)\n",
    "        dataframe = pd.DataFrame.from_dict(report_MultinomialNB)\n",
    "        dataframe.to_csv('BoW/MultinomialNB_clasification_report.csv', index=True)\n",
    "        save_classifier = open('BoW/MultinomialNB_classifier.pickle', 'wb')  #write in bytes\n",
    "        pickle.dump(result, save_classifier)\n",
    "        save_classifier.close()\n",
    "    elif name ==\"RandomForest\":\n",
    "        report_RandomForest = classification_report(Ytest, result, digits=4, output_dict=True)\n",
    "        print(report_RandomForest)\n",
    "        dataframe = pd.DataFrame.from_dict(report_RandomForest)\n",
    "        dataframe.to_csv('BoW/RandomForest_clasification_report.csv', index=True)\n",
    "        save_classifier = open('BoW/RandomForest_classifier.pickle', 'wb')  #write in bytes\n",
    "        pickle.dump(result, save_classifier)\n",
    "        save_classifier.close()\n",
    "    else:\n",
    "        report_LogisticRegression = classification_report(Ytest, result, digits=4, output_dict=True)\n",
    "        print(report_LogisticRegression)\n",
    "        dataframe = pd.DataFrame.from_dict(report_LogisticRegression)\n",
    "        dataframe.to_csv('BoW/LogisticRegression_clasification_report.csv', index=True)\n",
    "        save_classifier = open('BoW/LogisticRegression_classifier.pickle', 'wb')  #write in bytes\n",
    "        pickle.dump(result, save_classifier)\n",
    "        save_classifier.close()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Obteniendo resultados:\n",
      "---------- Modelo:  MLP  ---------- Time taken for prediction: 0.6775062084197998 seconds\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "       False     0.9995    0.9995    0.9995     54473\n",
      "        True     0.9501    0.9463    0.9482       503\n",
      "\n",
      "    accuracy                         0.9991     54976\n",
      "   macro avg     0.9748    0.9729    0.9739     54976\n",
      "weighted avg     0.9991    0.9991    0.9991     54976\n",
      " \n",
      "\n",
      "{'False': {'precision': 0.9995043597980725, 'recall': 0.9995410570374313, 'f1-score': 0.9995227080809193, 'support': 54473}, 'True': {'precision': 0.9500998003992016, 'recall': 0.9463220675944334, 'f1-score': 0.9482071713147411, 'support': 503}, 'accuracy': 0.9990541327124564, 'macro avg': {'precision': 0.974802080098637, 'recall': 0.9729315623159324, 'f1-score': 0.9738649396978302, 'support': 54976}, 'weighted avg': {'precision': 0.9990523353987413, 'recall': 0.9990541327124564, 'f1-score': 0.9990531992953876, 'support': 54976}}\n",
      "---------- Modelo:  SVM  ---------- Time taken for prediction: 313.21846866607666 seconds\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "       False     0.9991    1.0000    0.9995     54473\n",
      "        True     1.0000    0.9006    0.9477       503\n",
      "\n",
      "    accuracy                         0.9991     54976\n",
      "   macro avg     0.9995    0.9503    0.9736     54976\n",
      "weighted avg     0.9991    0.9991    0.9991     54976\n",
      " \n",
      "\n",
      "{'False': {'precision': 0.9990829558168113, 'recall': 1.0, 'f1-score': 0.999541267569452, 'support': 54473}, 'True': {'precision': 1.0, 'recall': 0.9005964214711729, 'f1-score': 0.9476987447698745, 'support': 503}, 'accuracy': 0.9990905122235157, 'macro avg': {'precision': 0.9995414779084056, 'recall': 0.9502982107355864, 'f1-score': 0.9736200061696633, 'support': 54976}, 'weighted avg': {'precision': 0.9990913462639908, 'recall': 0.9990905122235157, 'f1-score': 0.9990669371531214, 'support': 54976}}\n",
      "---------- Modelo:  LinearSVC  ---------- Time taken for prediction: 0.04690194129943848 seconds\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "       False     0.9993    0.9997    0.9995     54473\n",
      "        True     0.9649    0.9284    0.9463       503\n",
      "\n",
      "    accuracy                         0.9990     54976\n",
      "   macro avg     0.9821    0.9641    0.9729     54976\n",
      "weighted avg     0.9990    0.9990    0.9990     54976\n",
      " \n",
      "\n",
      "{'False': {'precision': 0.9993393525655142, 'recall': 0.9996879187854534, 'f1-score': 0.9995136052861011, 'support': 54473}, 'True': {'precision': 0.9648760330578512, 'recall': 0.9284294234592445, 'f1-score': 0.9463019250253292, 'support': 503}, 'accuracy': 0.9990359429569267, 'macro avg': {'precision': 0.9821076928116828, 'recall': 0.9640586711223489, 'f1-score': 0.9729077651557152, 'support': 54976}, 'weighted avg': {'precision': 0.9990240322491515, 'recall': 0.9990359429569267, 'f1-score': 0.9990267478361017, 'support': 54976}}\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "print(\"Obteniendo resultados:\")\n",
    "for (name, model) in models2:\n",
    "    start = time.time() # Star t time\n",
    "    result = model.predict(Xtest_bow)\n",
    "    end = time.time()\n",
    "    elapsed = end - start   \n",
    "    print(\"---------- Modelo: \", name, \" ---------- Time taken for prediction:\", elapsed,\"seconds\\n\", classification_report(Ytest, result, digits=4), \"\\n\")\n",
    "    \n",
    "    #Save classification report and trained model to BoW folder\n",
    "    if name ==\"MLP\":\n",
    "        report_MLP = classification_report(Ytest, result, digits=4, output_dict=True)\n",
    "        print(report_MLP)\n",
    "        dataframe = pd.DataFrame.from_dict(report_MLP)\n",
    "        dataframe.to_csv('BoW/MLP_clasification_report.csv', index=True)\n",
    "        save_classifier = open('BoW/MLP_classifier.pickle', 'wb')  #write in bytes\n",
    "        pickle.dump(result, save_classifier)\n",
    "        save_classifier.close()\n",
    "    elif name ==\"SVM\":\n",
    "        report_SVM = classification_report(Ytest, result, digits=4, output_dict=True)\n",
    "        print(report_SVM)\n",
    "        dataframe = pd.DataFrame.from_dict(report_SVM)\n",
    "        dataframe.to_csv('BoW/SVM_clasification_report.csv', index=True)\n",
    "        save_classifier = open('BoW/SVM_classifier.pickle', 'wb')  #write in bytes\n",
    "        pickle.dump(result, save_classifier)\n",
    "        save_classifier.close()\n",
    "    else:\n",
    "        report_LinearSVC = classification_report(Ytest, result, digits=4, output_dict=True)\n",
    "        print(report_LinearSVC)\n",
    "        dataframe = pd.DataFrame.from_dict(report_LinearSVC)\n",
    "        dataframe.to_csv('BoW/LinearSVC_clasification_report.csv', index=True)\n",
    "        save_classifier = open('BoW/LinearSVC_classifier.pickle', 'wb')  #write in bytes\n",
    "        pickle.dump(result, save_classifier)\n",
    "        save_classifier.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "#for (name, model) in models:\n",
    "\n",
    "save_classifier = open('saved_classifier_BoW1.pickle', 'wb')  #write in bytes\n",
    "pickle.dump(classifier, save_classifier)\n",
    "save_classifier.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "open_model = open('saved_classifier_BoW.pickle', 'rb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "EOFError",
     "evalue": "Ran out of input",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mEOFError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-20-13cce4c7c53b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mshow_model\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpickle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mopen_model\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mopen_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;31m#print(show_model)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mEOFError\u001b[0m: Ran out of input"
     ]
    }
   ],
   "source": [
    "show_model = pickle.load(open_model)\n",
    "open_model.close()\n",
    "#print(show_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tf-idf model (unbalanced, with all \"classic\" algorithms)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To compare with the results obtained, we will use the representation of the training and test data in Tf-idf format. To achieve this, the bag of words is transformed into the frequency of occurrence of terms in the collection of documents.<br>\n",
    "The process that is carried out, from this point on, is the same as the employee with the bag of words previously."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creando matriz de tf-idf...\n",
      "Wall time: 109 ms\n",
      "Wall time: 627 ms\n",
      "Wall time: 237 ms\n"
     ]
    }
   ],
   "source": [
    "\"\"\"tfidf = TfidfTransformer()\n",
    "\n",
    "print(\"Creando matriz de tf-idf...\")\n",
    "\n",
    "%time tfidf.fit(Xtrain_bow, Ytrain)\n",
    "%time Xtrain_tfidf = tfidf.transform(Xtrain_bow)\n",
    "%time Xtest_tfidf = tfidf.transform(Xtest_bow)\n",
    "\n",
    "scipy.sparse.save_npz('data/Xtrain_tfidf.npz', Xtrain_tfidf)\n",
    "scipy.sparse.save_npz('data/Xtest_tfidf.npz', Xtest_tfidf)\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This section, loads in memory the bags of words. Use only if you have previously obtained the bags of words and do not have them loaded into memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtest_tfidf = scipy.sparse.load_npz('data/Xtest_tfidf.npz').astype(np.float32)\n",
    "Xtrain_tfidf = scipy.sparse.load_npz('data/Xtrain_tfidf.npz').astype(np.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we create as many processes as we have estimators. These processes will be in charge of training the different models in parallel.<br> \n",
    "As a result, we get a list of tuples formed by: (the name of the algorithm, the model already trained)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_tfidf1 = Parallel(n_jobs=len(estimators1))(delayed(trainModel)(name, clazz, params, Xtrain_tfidf, Ytrain) for (name, (clazz, params)) in estimators1.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_tfidf2 = Parallel(n_jobs=len(estimators2))(delayed(trainModel)(name, clazz, params, Xtrain_tfidf, Ytrain) for (name, (clazz, params)) in estimators2.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('MLP', MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
      "              beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "              hidden_layer_sizes=100, learning_rate='constant',\n",
      "              learning_rate_init=0.001, max_fun=15000, max_iter=200,\n",
      "              momentum=0.9, n_iter_no_change=10, nesterovs_momentum=True,\n",
      "              power_t=0.5, random_state=None, shuffle=True, solver='adam',\n",
      "              tol=0.0001, validation_fraction=0.1, verbose=False,\n",
      "              warm_start=False)), ('SVM', SVC(C=1.0, break_ties=False, cache_size=1000, class_weight=None, coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='rbf',\n",
      "    max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "    tol=0.001, verbose=False)), ('LinearSVC', LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n",
      "          intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
      "          multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
      "          verbose=0))]\n"
     ]
    }
   ],
   "source": [
    "print(models_tfidf2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once the models are trained, we obtain the labels from the test set and evaluate the results of each of them. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Obteniendo resultados:\")\n",
    "for (name, model) in models_tfidf:\n",
    "    start = time.time() # Start time\n",
    "    if name == \"KNeighbors\":\n",
    "        result = [y for x in [Xtest_tfidf[i:i+5000,:] for i in range(0,Xtest_tfidf.shape[0],5000)] for y in model.predict(x)]\n",
    "    else:\n",
    "        result = model.predict(Xtest_tfidf)\n",
    "    end = time.time()\n",
    "    elapsed = end - start\n",
    "    print(\"---------- Modelo: \", name, \" ---------- Time taken for prediction:\", elapsed,\"seconds\\n\", classification_report(Ytest, result, digits=4), \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Obteniendo resultados:\n",
      "---------- Modelo:  KNeighbors  ---------- Time taken for prediction: 555.8283228874207 seconds\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "       False     0.9992    1.0000    0.9996     54473\n",
      "        True     0.9978    0.9085    0.9511       503\n",
      "\n",
      "    accuracy                         0.9991     54976\n",
      "   macro avg     0.9985    0.9543    0.9753     54976\n",
      "weighted avg     0.9991    0.9991    0.9991     54976\n",
      " \n",
      "\n",
      "{'False': {'precision': 0.9991562419751275, 'recall': 0.9999816422814972, 'f1-score': 0.9995687717334458, 'support': 54473}, 'True': {'precision': 0.9978165938864629, 'recall': 0.9085487077534792, 'f1-score': 0.9510926118626433, 'support': 503}, 'accuracy': 0.9991450814901047, 'macro avg': {'precision': 0.9984864179307953, 'recall': 0.9542651750174882, 'f1-score': 0.9753306917980445, 'support': 54976}, 'weighted avg': {'precision': 0.9991439849358996, 'recall': 0.9991450814901047, 'f1-score': 0.9991252416764206, 'support': 54976}}\n",
      "---------- Modelo:  MultinomialNB  ---------- Time taken for prediction: 0.06246685981750488 seconds\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "       False     0.9919    1.0000    0.9959     54473\n",
      "        True     1.0000    0.1173    0.2100       503\n",
      "\n",
      "    accuracy                         0.9919     54976\n",
      "   macro avg     0.9960    0.5586    0.6030     54976\n",
      "weighted avg     0.9920    0.9919    0.9887     54976\n",
      " \n",
      "\n",
      "{'False': {'precision': 0.9919150718356793, 'recall': 1.0, 'f1-score': 0.9959411280738641, 'support': 54473}, 'True': {'precision': 1.0, 'recall': 0.1172962226640159, 'f1-score': 0.2099644128113879, 'support': 503}, 'accuracy': 0.9919237485448196, 'macro avg': {'precision': 0.9959575359178396, 'recall': 0.558648111332008, 'f1-score': 0.6029527704426261, 'support': 54976}, 'weighted avg': {'precision': 0.9919890444576717, 'recall': 0.9919237485448196, 'f1-score': 0.9887498757496314, 'support': 54976}}\n",
      "---------- Modelo:  RandomForest  ---------- Time taken for prediction: 3.5929057598114014 seconds\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "       False     0.9989    1.0000    0.9995     54473\n",
      "        True     1.0000    0.8847    0.9388       503\n",
      "\n",
      "    accuracy                         0.9989     54976\n",
      "   macro avg     0.9995    0.9423    0.9691     54976\n",
      "weighted avg     0.9989    0.9989    0.9989     54976\n",
      " \n",
      "\n",
      "{'False': {'precision': 0.998936384808641, 'recall': 1.0, 'f1-score': 0.9994679094345161, 'support': 54473}, 'True': {'precision': 1.0, 'recall': 0.8846918489065606, 'f1-score': 0.9388185654008439, 'support': 503}, 'accuracy': 0.9989449941792782, 'macro avg': {'precision': 0.9994681924043205, 'recall': 0.9423459244532804, 'f1-score': 0.96914323741768, 'support': 54976}, 'weighted avg': {'precision': 0.9989461162994963, 'recall': 0.9989449941792782, 'f1-score': 0.9989130014737889, 'support': 54976}}\n",
      "---------- Modelo:  LogisticRegression  ---------- Time taken for prediction: 0.04686617851257324 seconds\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "       False     0.9998    0.9870    0.9933     54473\n",
      "        True     0.4090    0.9742    0.5761       503\n",
      "\n",
      "    accuracy                         0.9869     54976\n",
      "   macro avg     0.7044    0.9806    0.7847     54976\n",
      "weighted avg     0.9944    0.9869    0.9895     54976\n",
      " \n",
      "\n",
      "{'False': {'precision': 0.999758265461713, 'recall': 0.9870027353000569, 'f1-score': 0.9933395534452338, 'support': 54473}, 'True': {'precision': 0.4090150250417362, 'recall': 0.974155069582505, 'f1-score': 0.5761316872427983, 'support': 503}, 'accuracy': 0.9868851862630966, 'macro avg': {'precision': 0.7043866452517246, 'recall': 0.980578902441281, 'f1-score': 0.7847356203440161, 'support': 54976}, 'weighted avg': {'precision': 0.994353291474314, 'recall': 0.9868851862630966, 'f1-score': 0.989522332172318, 'support': 54976}}\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "print(\"Obteniendo resultados:\")\n",
    "for (name, model) in models_tfidf1:\n",
    "    start = time.time() # Star t time\n",
    "    if name ==\"KNeighbors\": \n",
    "        result = [y for x in [Xtest_bow[i:i+5000,:] for i in range(0,Xtest_bow.shape[0],5000)] for y in model.predict(x)]\n",
    "    else:\n",
    "        result = model.predict(Xtest_bow)\n",
    "    end = time.time()\n",
    "    elapsed = end - start   \n",
    "    print(\"---------- Modelo: \", name, \" ---------- Time taken for prediction:\", elapsed,\"seconds\\n\", classification_report(Ytest, result, digits=4), \"\\n\")\n",
    "    \n",
    "    #Save classification report and trained model to BoW folder\n",
    "    if name ==\"KNeighbors\": \n",
    "        report_KNeighbors = classification_report(Ytest, result, digits=4, output_dict=True)\n",
    "        print(report_KNeighbors)\n",
    "        dataframe = pd.DataFrame.from_dict(report_KNeighbors)\n",
    "        dataframe.to_csv('BoW_tfidf/KNeighbors_clasification_report.csv', index=True)\n",
    "        save_classifier = open('BoW_tfidf/KNeighbors_classifier.pickle', 'wb')  #write in bytes\n",
    "        pickle.dump(result, save_classifier)\n",
    "        save_classifier.close()\n",
    "    elif name ==\"MultinomialNB\":\n",
    "        report_MultinomialNB = classification_report(Ytest, result, digits=4, output_dict=True)\n",
    "        print(report_MultinomialNB)\n",
    "        dataframe = pd.DataFrame.from_dict(report_MultinomialNB)\n",
    "        dataframe.to_csv('BoW_tfidf/MultinomialNB_clasification_report.csv', index=True)\n",
    "        save_classifier = open('BoW_tfidf/MultinomialNB_classifier.pickle', 'wb')  #write in bytes\n",
    "        pickle.dump(result, save_classifier)\n",
    "        save_classifier.close()\n",
    "    elif name ==\"RandomForest\":\n",
    "        report_RandomForest = classification_report(Ytest, result, digits=4, output_dict=True)\n",
    "        print(report_RandomForest)\n",
    "        dataframe = pd.DataFrame.from_dict(report_RandomForest)\n",
    "        dataframe.to_csv('BoW_tfidf/RandomForest_clasification_report.csv', index=True)\n",
    "        save_classifier = open('BoW_tfidf/RandomForest_classifier.pickle', 'wb')  #write in bytes\n",
    "        pickle.dump(result, save_classifier)\n",
    "        save_classifier.close()\n",
    "    else:\n",
    "        report_LogisticRegression = classification_report(Ytest, result, digits=4, output_dict=True)\n",
    "        print(report_LogisticRegression)\n",
    "        dataframe = pd.DataFrame.from_dict(report_LogisticRegression)\n",
    "        dataframe.to_csv('BoW_tfidf/LogisticRegression_clasification_report.csv', index=True)\n",
    "        save_classifier = open('BoW_tfidf/LogisticRegression_classifier.pickle', 'wb')  #write in bytes\n",
    "        pickle.dump(result, save_classifier)\n",
    "        save_classifier.close()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Obteniendo resultados:\n",
      "---------- Modelo:  MLP  ---------- Time taken for prediction: 0.6115198135375977 seconds\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "       False     0.9998    0.9287    0.9630     54473\n",
      "        True     0.1131    0.9841    0.2028       503\n",
      "\n",
      "    accuracy                         0.9292     54976\n",
      "   macro avg     0.5565    0.9564    0.5829     54976\n",
      "weighted avg     0.9917    0.9292    0.9560     54976\n",
      " \n",
      "\n",
      "{'False': {'precision': 0.9998418909838334, 'recall': 0.9287169790538432, 'f1-score': 0.9629678978976121, 'support': 54473}, 'True': {'precision': 0.11306532663316583, 'recall': 0.9840954274353877, 'f1-score': 0.20282728948985865, 'support': 503}, 'accuracy': 0.929223661233993, 'macro avg': {'precision': 0.5564536088084996, 'recall': 0.9564062032446154, 'f1-score': 0.5828975936937354, 'support': 54976}, 'weighted avg': {'precision': 0.9917283757795917, 'recall': 0.929223661233993, 'f1-score': 0.9560130316645449, 'support': 54976}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\apula\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------- Modelo:  SVM  ---------- Time taken for prediction: 128.29665064811707 seconds\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "       False     0.9909    1.0000    0.9954     54473\n",
      "        True     0.0000    0.0000    0.0000       503\n",
      "\n",
      "    accuracy                         0.9909     54976\n",
      "   macro avg     0.4954    0.5000    0.4977     54976\n",
      "weighted avg     0.9818    0.9909    0.9863     54976\n",
      " \n",
      "\n",
      "{'False': {'precision': 0.990850552968568, 'recall': 1.0, 'f1-score': 0.9954042522087913, 'support': 54473}, 'True': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 503}, 'accuracy': 0.990850552968568, 'macro avg': {'precision': 0.495425276484284, 'recall': 0.5, 'f1-score': 0.4977021261043956, 'support': 54976}, 'weighted avg': {'precision': 0.9817848183181171, 'recall': 0.990850552968568, 'f1-score': 0.9862968537283449, 'support': 54976}}\n",
      "---------- Modelo:  LinearSVC  ---------- Time taken for prediction: 0.03124260902404785 seconds\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "       False     0.9996    0.9746    0.9869     54473\n",
      "        True     0.2590    0.9622    0.4081       503\n",
      "\n",
      "    accuracy                         0.9745     54976\n",
      "   macro avg     0.6293    0.9684    0.6975     54976\n",
      "weighted avg     0.9929    0.9745    0.9817     54976\n",
      " \n",
      "\n",
      "{'False': {'precision': 0.9996422317208654, 'recall': 0.9745745598736989, 'f1-score': 0.9869492470719465, 'support': 54473}, 'True': {'precision': 0.25896201177100053, 'recall': 0.9622266401590457, 'f1-score': 0.4080944350758854, 'support': 503}, 'accuracy': 0.9744615832363213, 'macro avg': {'precision': 0.6293021217459329, 'recall': 0.9684006000163723, 'f1-score': 0.6975218410739159, 'support': 54976}, 'weighted avg': {'precision': 0.9928654172812047, 'recall': 0.9744615832363213, 'f1-score': 0.9816530456306991, 'support': 54976}}\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "print(\"Obteniendo resultados:\")\n",
    "for (name, model) in models_tfidf2:\n",
    "    start = time.time() # Star t time\n",
    "    result = model.predict(Xtest_bow)\n",
    "    end = time.time()\n",
    "    elapsed = end - start   \n",
    "    print(\"---------- Modelo: \", name, \" ---------- Time taken for prediction:\", elapsed,\"seconds\\n\", classification_report(Ytest, result, digits=4), \"\\n\")\n",
    "    \n",
    "    #Save classification report and trained model to BoW folder\n",
    "    if name ==\"MLP\":\n",
    "        report_MLP = classification_report(Ytest, result, digits=4, output_dict=True)\n",
    "        print(report_MLP)\n",
    "        dataframe = pd.DataFrame.from_dict(report_MLP)\n",
    "        dataframe.to_csv('BoW_tfidf/MLP_clasification_report.csv', index=True)\n",
    "        save_classifier = open('BoW_tfidf/MLP_classifier.pickle', 'wb')  #write in bytes\n",
    "        pickle.dump(result, save_classifier)\n",
    "        save_classifier.close()\n",
    "    elif name ==\"SVM\":\n",
    "        report_SVM = classification_report(Ytest, result, digits=4, output_dict=True)\n",
    "        print(report_SVM)\n",
    "        dataframe = pd.DataFrame.from_dict(report_SVM)\n",
    "        dataframe.to_csv('BoW_tfidf/SVM_clasification_report.csv', index=True)\n",
    "        save_classifier = open('BoW_tfidf/SVM_classifier.pickle', 'wb')  #write in bytes\n",
    "        pickle.dump(result, save_classifier)\n",
    "        save_classifier.close()\n",
    "    else:\n",
    "        report_LinearSVC = classification_report(Ytest, result, digits=4, output_dict=True)\n",
    "        print(report_LinearSVC)\n",
    "        dataframe = pd.DataFrame.from_dict(report_LinearSVC)\n",
    "        dataframe.to_csv('BoW_tfidf/LinearSVC_clasification_report.csv', index=True)\n",
    "        save_classifier = open('BoW_tfidf/LinearSVC_classifier.pickle', 'wb')  #write in bytes\n",
    "        pickle.dump(result, save_classifier)\n",
    "        save_classifier.close()    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Voting (Bag of Words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VotingClassifier - Time taken for training: 10572.805789470673 seconds\n"
     ]
    }
   ],
   "source": [
    "ensemble = VotingClassifier(models, n_jobs=-1)\n",
    "start = time.time() # Start time\n",
    "voting_model_bow=ensemble.fit(Xtrain_bow,Ytrain)\n",
    "end = time.time()\n",
    "elapsed = end - start\n",
    "print(\"VotingClassifier - Time taken for training:\", elapsed, \"seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "warnings.filterwarnings(module='sklearn*', action='ignore', category=DeprecationWarning)\n",
    "start = time.time() # Start time\n",
    "predictions1 = [y for x in [Xtest_bow[i:i+2000,:] for i in range(0,Xtest_bow.shape[0],2000)] for y in voting_model_bow.predict(x)]\n",
    "end = time.time()\n",
    "elapsed = end - start\n",
    "print(\"VotingClassifier - Time taken for prediction:\", elapsed, \"seconds\")\n",
    "cr1=classification_report(Ytest, predictions1, digits=4)\n",
    "print(cr1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Voting (Tf-idf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ensemble = VotingClassifier(models_tfidf, n_jobs=-1)\n",
    "start = time.time() # Start time\n",
    "voting_model_tfidf=ensemble.fit(Xtrain_tfidf,Ytrain)\n",
    "end = time.time()\n",
    "elapsed = end - start\n",
    "print(\"VotingClassifier - Time taken for training:\", elapsed, \"seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "warnings.filterwarnings(module='sklearn*', action='ignore', category=DeprecationWarning)\n",
    "start = time.time() # Start time\n",
    "predictions2 = [y for x in [Xtest_tfidf[i:i+2000,:] for i in range(0,Xtest_tfidf.shape[0],2000)] for y in voting_model_tfidf.predict(x)]\n",
    "end = time.time()\n",
    "elapsed = end - start\n",
    "print(\"VotingClassifier - Time taken for prediction:\", elapsed, \"seconds\")\n",
    "cr2=classification_report(Ytest, predictions2, digits=4)\n",
    "print(cr2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
